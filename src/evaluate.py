import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import tqdm
import argparse
import os

# Import hÃ m load model tá»« classifier.py
from classifier import load_trained_classifier

def parse_args():
    parser = argparse.ArgumentParser(description="Evaluate the animal classifier on Test set")
    parser.add_argument('--data_dir', type=str, required=True, help='Path to the dataset directory (containing test folder)')
    parser.add_argument('--model_name', type=str, default='resnet50', help='resnet50, mobilenet, vgg16')
    parser.add_argument('--model_path', type=str, default='models/best_animal_classifier.pth', help='Path to the trained model weights')
    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for evaluation')
    parser.add_argument('--device', type=str, default='cuda', help='Device to run evaluation on')
    return parser.parse_args()

def main():
    args = parse_args()
    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    
    print(f"Using device: {device}")

    # 1. Chuáº©n bá»‹ dá»¯ liá»‡u Test
    # LÆ¯U Ã: Test set chá»‰ Resize vÃ  Crop, KHÃ”NG Ä‘Æ°á»£c Random Flip hay Augmentation
    test_transforms = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    test_dir = os.path.join(args.data_dir, 'test')
    if not os.path.exists(test_dir):
        print(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c test táº¡i {test_dir}")
        return

    test_dataset = datasets.ImageFolder(test_dir, test_transforms)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)

    class_names = test_dataset.classes
    num_classes = len(class_names)
    print(f"Evaluating on {len(test_dataset)} images of {num_classes} classes.")

    # 2. Táº£i mÃ´ hÃ¬nh
    print(f"Loading model {args.model_name} from {args.model_path}...")
    try:
        model = load_trained_classifier(args.model_path, args.model_name, num_classes, device)
    except Exception as e:
        print(f"âŒ Lá»—i khi táº£i model: {e}")
        print("ðŸ’¡ Gá»£i Ã½: Kiá»ƒm tra xem --model_name cÃ³ khá»›p vá»›i file weights khÃ´ng?")
        return

    # 3. VÃ²ng láº·p Ä‘Ã¡nh giÃ¡
    running_corrects = 0
    
    # Biáº¿n Ä‘á»ƒ tÃ­nh Ä‘á»™ chÃ­nh xÃ¡c tá»«ng lá»›p
    class_correct = list(0. for i in range(num_classes))
    class_total = list(0. for i in range(num_classes))

    print("\nBáº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡...")
    with torch.no_grad(): # KhÃ´ng tÃ­nh gradient Ä‘á»ƒ tiáº¿t kiá»‡m bá»™ nhá»›
        for inputs, labels in tqdm(test_loader, desc="Testing"):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            # TÃ­nh tá»•ng sá»‘ Ä‘Ãºng
            running_corrects += torch.sum(preds == labels.data)
            
            # TÃ­nh Ä‘Ãºng cho tá»«ng lá»›p
            c = (preds == labels).squeeze()

            # Xá»­ lÃ½ trÆ°á»ng há»£p batch cuá»‘i cÃ¹ng cÃ³ thá»ƒ cÃ³ kÃ­ch thÆ°á»›c nhá» hÆ¡n
            if inputs.size(0) == 1: # Náº¿u batch chá»‰ cÃ³ 1 áº£nh
                 label = labels.item()
                 class_correct[label] += c.item()
                 class_total[label] += 1
            else:
                for i in range(inputs.size(0)):
                    label = labels[i].item()
                    class_correct[label] += c[i].item()
                    class_total[label] += 1

    # 4. In káº¿t quáº£ tá»•ng thá»ƒ
    total_acc = running_corrects.double() / len(test_dataset)
    print('-' * 40)
    print(f'ðŸ”¥ Tá»”NG Káº¾T QUáº¢ TRÃŠN Táº¬P TEST:')
    print(f'ðŸ‘‰ Overall Accuracy: {total_acc:.2%}')
    print('-' * 40)

    # 5. In káº¿t quáº£ chi tiáº¿t tá»«ng lá»›p (Optional)
    print("\nChi tiáº¿t tá»«ng lá»›p:")
    for i in range(num_classes):
        if class_total[i] > 0:
            acc = 100 * class_correct[i] / class_total[i]
            print(f' - {class_names[i]:<15s}: {acc:.2f}% ({int(class_correct[i])}/{int(class_total[i])})')
        else:
            print(f' - {class_names[i]:<15s}: N/A (no images)')

if __name__ == '__main__':
    main()